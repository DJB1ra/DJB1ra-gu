{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49c84375-3b26-4092-b6dc-fd169f2dd269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bd545e-94d2-4fbc-8126-b6442292050f",
   "metadata": {
    "tags": []
   },
   "source": [
    "<H2> Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3adf20d0-6ada-427c-aeb6-57dccb1a6c04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 2\n",
      "Classes: ['MEL', 'NV']\n",
      "Number of training images: 6426\n",
      "Number of training subset images: 1285\n",
      "Number of validation images: 1252\n"
     ]
    }
   ],
   "source": [
    "#transform to 224, 224 since VGG expect that size\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),           # Convert images to PyTorch tensors\n",
    "])\n",
    "\n",
    "# Define paths to your train and validation data\n",
    "train_path = \"train\"\n",
    "val_path = \"val\"\n",
    "\n",
    "#define train and valdataset again but with transoformers this time\n",
    "train_dataset = ImageFolder(train_path, transform=transform)\n",
    "val_dataset = ImageFolder(val_path, transform=transform)\n",
    "\n",
    "#8 batch size to reduce training time\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#20% of training since otherwise it would have taken a day to train\n",
    "subset_size = int(0.2 * len(train_dataset))\n",
    "\n",
    "# Randomly select a subset of indices from the training dataset\n",
    "subset_indices = np.random.choice(len(train_dataset), subset_size, replace=False)\n",
    "\n",
    "# Create a subset of the training dataset using the selected indices\n",
    "train_subset = Subset(train_dataset, subset_indices)\n",
    "\n",
    "# Use DataLoader to load the subset of data in batches\n",
    "train_loader_subset = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Print dataset details\n",
    "print(\"Number of classes:\", len(train_dataset.classes))\n",
    "print(\"Classes:\", train_dataset.classes)\n",
    "print(\"Number of training images:\", len(train_dataset))\n",
    "print(\"Number of training subset images:\", len(train_subset))\n",
    "print(\"Number of validation images:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8346b786-f856-4bbc-88a7-a53c0e7c1c39",
   "metadata": {},
   "source": [
    "<h2> Some baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83d47974-c009-466f-832c-39c804396488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "897eadaf-dbed-4e13-a404-5727b532043f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the model\n",
    "num_classes = len(train_dataset.classes)\n",
    "model = SimpleCNN(num_classes).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9741667-15d8-425c-9fc5-cc70ff15e01f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 (Training): 100%|██████████| 804/804 [00:46<00:00, 17.47batch/s, accuracy=0.744, loss=0.505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Training Loss: 2.5237, Training Accuracy: 74.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 (Validation): 100%|██████████| 157/157 [00:03<00:00, 45.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Validation Loss: 0.4728, Validation Accuracy: 76.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 (Training): 100%|██████████| 804/804 [00:32<00:00, 24.58batch/s, accuracy=0.778, loss=0.442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Training Loss: 2.2081, Training Accuracy: 77.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 (Validation): 100%|██████████| 157/157 [00:02<00:00, 55.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Validation Loss: 0.4327, Validation Accuracy: 77.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 (Training): 100%|██████████| 804/804 [00:32<00:00, 24.59batch/s, accuracy=0.798, loss=0.418]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Training Loss: 2.0924, Training Accuracy: 79.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 (Validation): 100%|██████████| 157/157 [00:02<00:00, 55.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Validation Loss: 0.4555, Validation Accuracy: 77.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 (Training): 100%|██████████| 804/804 [00:32<00:00, 24.45batch/s, accuracy=0.785, loss=0.447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Training Loss: 2.2353, Training Accuracy: 78.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 (Validation): 100%|██████████| 157/157 [00:02<00:00, 55.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Validation Loss: 0.4542, Validation Accuracy: 77.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 (Training): 100%|██████████| 804/804 [00:32<00:00, 24.62batch/s, accuracy=0.786, loss=0.442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Training Loss: 2.2127, Training Accuracy: 78.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 (Validation): 100%|██████████| 157/157 [00:02<00:00, 55.58batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Validation Loss: 0.4303, Validation Accuracy: 77.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Training)\", unit=\"batch\") as t:\n",
    "        for inputs, labels in t:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            t.set_postfix(loss=running_loss / total, accuracy=correct / total)\n",
    "\n",
    "    # Print training statistics\n",
    "    epoch_loss = running_loss / len(train_subset)\n",
    "    epoch_acc = correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_acc:.2%}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Validation)\", unit=\"batch\"):\n",
    "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "            val_outputs = model(val_inputs)\n",
    "            val_loss += criterion(val_outputs, val_labels).item() * val_inputs.size(0)\n",
    "            _, val_predicted = torch.max(val_outputs, 1)\n",
    "            val_total += val_labels.size(0)\n",
    "            val_correct += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "    # Print validation statistics\n",
    "    val_epoch_loss = val_loss / len(val_dataset)\n",
    "    val_epoch_acc = val_correct / val_total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d88bdb",
   "metadata": {},
   "source": [
    "## Baseline model with batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7881d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNNwithBN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNNwithBN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)  \n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)  \n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)  \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))  \n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))  \n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))  \n",
    "        x = x.view(-1, 64 * 28 * 28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b837adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the model\n",
    "num_classes = len(train_dataset.classes)\n",
    "model = SimpleCNNwithBN(num_classes).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcdefeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 (Training): 100%|██████████| 804/804 [00:38<00:00, 20.68batch/s, accuracy=0.726, loss=1.3] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Training Loss: 6.5191, Training Accuracy: 72.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 (Validation): 100%|██████████| 157/157 [00:03<00:00, 43.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Validation Loss: 0.4328, Validation Accuracy: 77.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 (Training): 100%|██████████| 804/804 [00:36<00:00, 21.80batch/s, accuracy=0.755, loss=0.492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Training Loss: 2.4604, Training Accuracy: 75.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 (Validation): 100%|██████████| 157/157 [00:03<00:00, 47.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Validation Loss: 0.4203, Validation Accuracy: 75.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 (Training): 100%|██████████| 804/804 [00:36<00:00, 22.15batch/s, accuracy=0.747, loss=0.514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Training Loss: 2.5727, Training Accuracy: 74.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 (Validation): 100%|██████████| 157/157 [00:03<00:00, 50.87batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Validation Loss: 0.4826, Validation Accuracy: 70.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 (Training): 100%|██████████| 804/804 [00:36<00:00, 21.78batch/s, accuracy=0.717, loss=0.509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Training Loss: 2.5435, Training Accuracy: 71.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 (Validation): 100%|██████████| 157/157 [00:03<00:00, 49.39batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Validation Loss: 0.4470, Validation Accuracy: 71.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 (Training): 100%|██████████| 804/804 [00:35<00:00, 22.72batch/s, accuracy=0.719, loss=0.53] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Training Loss: 2.6504, Training Accuracy: 71.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 (Validation): 100%|██████████| 157/157 [00:02<00:00, 52.64batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Validation Loss: 0.4829, Validation Accuracy: 78.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Training)\", unit=\"batch\") as t:\n",
    "        for inputs, labels in t:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            t.set_postfix(loss=running_loss / total, accuracy=correct / total)\n",
    "\n",
    "    # Print training statistics\n",
    "    epoch_loss = running_loss / len(train_subset)\n",
    "    epoch_acc = correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}, Training Accuracy: {epoch_acc:.2%}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Validation)\", unit=\"batch\"):\n",
    "            val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "            val_outputs = model(val_inputs)\n",
    "            val_loss += criterion(val_outputs, val_labels).item() * val_inputs.size(0)\n",
    "            _, val_predicted = torch.max(val_outputs, 1)\n",
    "            val_total += val_labels.size(0)\n",
    "            val_correct += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "    # Print validation statistics\n",
    "    val_epoch_loss = val_loss / len(val_dataset)\n",
    "    val_epoch_acc = val_correct / val_total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea11815-7ad0-496a-8dcb-b5d63b60cf4c",
   "metadata": {},
   "source": [
    "<h2> VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "532fadce-db7b-4f29-9b56-6b143df39a03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "num_cpu_cores = os.cpu_count()\n",
    "print(num_cpu_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7ae3aea-f251-4c7f-adb3-c019873951c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_transforms = transforms.RandomApply([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.15, saturation=0.1, hue=0.1)\n",
    "], p=0.2)  # Apply each transformation with 20% probability\n",
    "\n",
    "# Use the provided vggtransforms for preprocessing\n",
    "transform = transforms.Compose([\n",
    "    random_transforms,               # Apply random transformations for data augmentation\n",
    "    transforms.Resize((224, 224)),   # Resize images to 224x224\n",
    "    transforms.ToTensor(),           # Convert images to PyTorch tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  #preprocess images according to\n",
    "    #imagenet numbers\n",
    "])\n",
    "\n",
    "#define train and valdataset again but with complex transformers\n",
    "#need to redefine everything so the new transformers are applied correctly\n",
    "train_dataset = ImageFolder(train_path, transform=transform)\n",
    "val_dataset = ImageFolder(val_path, transform=transform)\n",
    "\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_cpu_cores)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_cpu_cores)\n",
    "\n",
    "subset_size = int(0.2 * len(train_dataset))\n",
    "\n",
    "subset_indices = np.random.choice(len(train_dataset), subset_size, replace=False)\n",
    "\n",
    "train_subset = Subset(train_dataset, subset_indices)\n",
    "\n",
    "train_loader_subset = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=num_cpu_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4aa2e9d6-fb80-4899-92c2-d35a8c007fbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#load in weights from the model\n",
    "weights_id = torchvision.models.VGG16_Weights.IMAGENET1K_V1\n",
    "\n",
    "vggmodel = models.vgg16(weights=weights_id)\n",
    "vggmodel.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Freeze all layers except the last classifier layer\n",
    "for param in vggmodel.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the last classifier layer\n",
    "for param in vggmodel.classifier[6].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Modify the classifier layer\n",
    "num_features = vggmodel.classifier[6].in_features\n",
    "vggmodel.classifier[6] = nn.Linear(num_features, len(train_dataset.classes))\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vgg_model = vggmodel.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(vggmodel.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4049571d-f6f6-47e5-bd7c-95643f98779f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 804/804 [01:48<00:00,  7.42batch/s, accuracy=0.796, loss=0.454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 2.2712, Train Accuracy: 79.65%, Val Accuracy: 82.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 804/804 [01:47<00:00,  7.47batch/s, accuracy=0.801, loss=0.466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 2.3298, Train Accuracy: 80.14%, Val Accuracy: 80.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 804/804 [01:47<00:00,  7.46batch/s, accuracy=0.814, loss=0.442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 2.2089, Train Accuracy: 81.37%, Val Accuracy: 81.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 804/804 [01:47<00:00,  7.47batch/s, accuracy=0.811, loss=0.475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 2.3755, Train Accuracy: 81.09%, Val Accuracy: 82.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 804/804 [01:47<00:00,  7.45batch/s, accuracy=0.805, loss=0.487]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 2.4351, Train Accuracy: 80.55%, Val Accuracy: 83.87%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    vgg_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    # Initialize tqdm progress bar\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as t:\n",
    "        for inputs, labels in t:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = vgg_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update tqdm progress bar\n",
    "            t.set_postfix(loss=running_loss / total_train, accuracy=correct_train / total_train)\n",
    "\n",
    "    # Calculate training accuracy\n",
    "    train_accuracy = correct_train / total_train\n",
    "\n",
    "    # Validation phase\n",
    "    vgg_model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = vgg_model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate validation accuracy\n",
    "    val_accuracy = correct_val / total_val\n",
    "\n",
    "    # Print epoch statistics\n",
    "    epoch_loss = running_loss / len(train_subset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Train Accuracy: {train_accuracy:.2%}, Val Accuracy: {val_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d3a3e1-ee16-4b5e-a10c-42cc501ae511",
   "metadata": {},
   "source": [
    "Epoch [5/5], Loss: 2.3846, Train Accuracy: 80.91%, Val Accuracy: 80.43% all transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6da4b80-54eb-43db-a587-18aab19516ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 157/157 [00:21<00:00,  7.29batch/s, accuracy=0.842, loss=0.358]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3579, Validation Accuracy: 84.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "vggmodel.eval()\n",
    "\n",
    "# Variables to keep track of accuracy and loss\n",
    "val_loss = 0.0\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "\n",
    "# Use tqdm for progress bar\n",
    "with tqdm(val_loader, desc=\"Validation\", unit=\"batch\") as t:\n",
    "    # Disable gradient computation for validation\n",
    "    with torch.no_grad():\n",
    "        # Iterate over the validation set\n",
    "        for inputs, labels in t:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = vggmodel(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Compute loss\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update tqdm progress bar\n",
    "            t.set_postfix(loss=val_loss / val_total, accuracy=val_correct / val_total)\n",
    "\n",
    "# Calculate average loss and accuracy\n",
    "avg_val_loss = val_loss / len(val_dataset)\n",
    "val_accuracy = val_correct / val_total\n",
    "\n",
    "# Print validation results\n",
    "print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e80f7b6-6cbc-4775-904f-c3c120d43b65",
   "metadata": {},
   "source": [
    "<H2> ResNet Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13bf196d-dd50-4687-b49f-ece66bbe0499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define settings\n",
    "use_data_augmentation = True\n",
    "use_batch_norm = True\n",
    "use_weight_decay = True\n",
    "use_subset_training = True\n",
    "batch_size = 8\n",
    "lr = 0.0001\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cc673c6-dd1a-4cd7-8a3b-a00cc40aa936",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "random_transforms = transforms.RandomApply([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.15, saturation=0.1, hue=0.1)\n",
    "], p=0.2) if use_data_augmentation else None\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    random_transforms,\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd727c11-6d00-40ba-8366-813a741db913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(train_path, transform=transform)\n",
    "val_dataset = ImageFolder(val_path, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_cpu_cores)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_cpu_cores)\n",
    "\n",
    "# Subset training data if enabled\n",
    "if use_subset_training:\n",
    "    subset_size = int(0.2 * len(train_dataset))\n",
    "    subset_indices = np.random.choice(len(train_dataset), subset_size, replace=False)\n",
    "    train_subset = Subset(train_dataset, subset_indices)\n",
    "    train_loader_subset = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=num_cpu_cores)\n",
    "else:\n",
    "    train_loader_subset = train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9718073e-342a-4fa3-9dd4-b3bee6f9c625",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet model\n",
    "resnet_model = models.resnet18(weights=True)\n",
    "\n",
    "# Freeze the parameters of the model\n",
    "if not use_batch_norm:\n",
    "   # Unfreeze last layer\n",
    "    for param in resnet_model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Add batch normalization if enabled\n",
    "if use_batch_norm:\n",
    "    for param in resnet_model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "    for module in resnet_model.modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            module.add_module('batch_norm', nn.BatchNorm2d(module.out_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab1a55e3-2013-433f-b2b6-d68d52add96d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modify the classifier layer\n",
    "num_features = resnet_model.fc.in_features\n",
    "resnet_model.fc = nn.Linear(num_features, len(train_dataset.classes))\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "resnet_model = resnet_model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_params = {'lr': lr}\n",
    "if use_weight_decay:\n",
    "    optimizer_params['weight_decay'] = 0.0001\n",
    "optimizer = optim.Adam(resnet_model.parameters(), **optimizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67d8ac7e-65e1-4afb-90bb-7724002a519f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 804/804 [01:18<00:00, 10.24batch/s, accuracy=0.823, loss=0.396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.9795, Train Accuracy: 82.32%, Val Accuracy: 85.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 804/804 [01:17<00:00, 10.43batch/s, accuracy=0.858, loss=0.33] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 1.6496, Train Accuracy: 85.84%, Val Accuracy: 86.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 804/804 [01:17<00:00, 10.34batch/s, accuracy=0.87, loss=0.295] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 1.4766, Train Accuracy: 87.02%, Val Accuracy: 85.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 804/804 [01:14<00:00, 10.72batch/s, accuracy=0.898, loss=0.248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 1.2416, Train Accuracy: 89.82%, Val Accuracy: 87.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 804/804 [01:14<00:00, 10.74batch/s, accuracy=0.911, loss=0.213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 1.0647, Train Accuracy: 91.13%, Val Accuracy: 88.58%\n",
      "Validation Accuracy: 88.62%\n",
      "Confusion Matrix:\n",
      "[[557  69]\n",
      " [ 73 553]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    resnet_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    # Initialize tqdm progress bar\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as t:\n",
    "        for inputs, labels in t:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = resnet_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update tqdm progress bar\n",
    "            t.set_postfix(loss=running_loss / total_train, accuracy=correct_train / total_train)\n",
    "\n",
    "    # Calculate training accuracy\n",
    "    train_accuracy = correct_train / total_train\n",
    "\n",
    "    # Validation phase\n",
    "    resnet_model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = resnet_model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate validation accuracy\n",
    "    val_accuracy = correct_val / total_val\n",
    "\n",
    "    # Print epoch statistics\n",
    "    epoch_loss = running_loss / len(train_subset) if use_subset_training else running_loss / len(train_dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Train Accuracy: {train_accuracy:.2%}, Val Accuracy: {val_accuracy:.2%}\")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = resnet_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Convert tensors to numpy arrays and store in lists\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        predicted_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "        total_val += labels.size(0)\n",
    "        correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate validation accuracy\n",
    "val_accuracy = correct_val / total_val\n",
    "\n",
    "# Print validation accuracy\n",
    "print(f\"Validation Accuracy: {val_accuracy:.2%}\")\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927fef56-59b3-4b9a-b7a9-526d77b9b6fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a directory to save misclassified images\n",
    "output_dir = 'misclassified_images'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Lists to store misclassified image paths, labels, and predictions\n",
    "misclassified_image_paths = []\n",
    "misclassified_labels = []\n",
    "misclassified_predictions = []\n",
    "\n",
    "# Validation phase\n",
    "resnet_model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = resnet_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_val += labels.size(0)\n",
    "        correct_val += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Find misclassified images\n",
    "        misclassified_mask = predicted != labels\n",
    "        misclassified_images = inputs[misclassified_mask]\n",
    "        misclassified_labels.extend(labels[misclassified_mask].tolist())\n",
    "        misclassified_predictions.extend(predicted[misclassified_mask].tolist())\n",
    "        \n",
    "        # Save misclassified images\n",
    "        for i, image in enumerate(misclassified_images):\n",
    "            image_path = os.path.join(output_dir, f'misclassified_{len(misclassified_image_paths) + 1}.png')\n",
    "            misclassified_image_paths.append(image_path)\n",
    "            \n",
    "            # Normalize image pixel values to the range [0, 1]\n",
    "            image = image.cpu().numpy().transpose((1, 2, 0))\n",
    "            image = (image - image.min()) / (image.max() - image.min())\n",
    "            \n",
    "            plt.imsave(image_path, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef3c473-0be3-4a24-9861-6a540f6c55be",
   "metadata": {},
   "source": [
    "## Resnet without data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b83f4cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define settings\n",
    "use_batch_norm = True\n",
    "use_weight_decay = True\n",
    "use_subset_training = True\n",
    "batch_size = 8\n",
    "lr = 0.0001\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7d6cc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ImageFolder(train_path, transform=transform)\n",
    "val_dataset = ImageFolder(val_path, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98945c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet model\n",
    "resnet_model = models.resnet18(weights=True)\n",
    "\n",
    "# Freeze the parameters of the model\n",
    "if not use_batch_norm:\n",
    "   # Unfreeze last layer\n",
    "    for param in resnet_model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Add batch normalization if enabled\n",
    "if use_batch_norm:\n",
    "    for param in resnet_model.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "    for module in resnet_model.modules():\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            module.add_module('batch_norm', nn.BatchNorm2d(module.out_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77b30ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the classifier layer\n",
    "num_features = resnet_model.fc.in_features\n",
    "resnet_model.fc = nn.Linear(num_features, len(train_dataset.classes))\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "resnet_model = resnet_model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_params = {'lr': lr}\n",
    "if use_weight_decay:\n",
    "    optimizer_params['weight_decay'] = 0.0001\n",
    "optimizer = optim.Adam(resnet_model.parameters(), **optimizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16b8e9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 804/804 [01:02<00:00, 12.89batch/s, accuracy=0.819, loss=0.395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.9751, Train Accuracy: 81.95%, Val Accuracy: 85.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 804/804 [01:01<00:00, 13.15batch/s, accuracy=0.866, loss=0.308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 1.5396, Train Accuracy: 86.57%, Val Accuracy: 85.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 804/804 [01:01<00:00, 12.98batch/s, accuracy=0.896, loss=0.255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 1.2748, Train Accuracy: 89.59%, Val Accuracy: 86.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 804/804 [01:01<00:00, 13.10batch/s, accuracy=0.914, loss=0.21] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 1.0521, Train Accuracy: 91.36%, Val Accuracy: 87.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 804/804 [01:01<00:00, 12.97batch/s, accuracy=0.942, loss=0.157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 0.7868, Train Accuracy: 94.18%, Val Accuracy: 85.78%\n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "predicted_labels = []\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    resnet_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    # Initialize tqdm progress bar\n",
    "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as t:\n",
    "        for inputs, labels in t:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = resnet_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update tqdm progress bar\n",
    "            t.set_postfix(loss=running_loss / total_train, accuracy=correct_train / total_train)\n",
    "\n",
    "    # Calculate training accuracy\n",
    "    train_accuracy = correct_train / total_train\n",
    "\n",
    "    # Validation phase\n",
    "    resnet_model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = resnet_model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate validation accuracy\n",
    "    val_accuracy = correct_val / total_val\n",
    "\n",
    "    # Print epoch statistics\n",
    "    epoch_loss = running_loss / len(train_subset) if use_subset_training else running_loss / len(train_dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Train Accuracy: {train_accuracy:.2%}, Val Accuracy: {val_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6547c85e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

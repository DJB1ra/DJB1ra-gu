{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b33cc24c-5f07-49b1-b3df-e186facd9dd9",
   "metadata": {},
   "source": [
    "<h3>Task 1: A classification example: fetal heart condition diagnosis</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaf41f8-3e50-414c-ac2b-c13fdff6d6ec",
   "metadata": {},
   "source": [
    "Step 1. Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "103fc6a5-bed3-4371-bd49-f01b8f1c6fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "# Read the CSV file.\n",
    "data = pd.read_csv('ctg.csv', skiprows=1)\n",
    "\n",
    "# Select the relevant numerical columns.\n",
    "selected_cols = ['LB', 'AC', 'FM', 'UC', 'DL', 'DS', 'DP', 'ASTV', 'MSTV', 'ALTV',\n",
    "                 'MLTV', 'Width', 'Min', 'Max', 'Nmax', 'Nzeros', 'Mode', 'Mean',\n",
    "                 'Median', 'Variance', 'Tendency', 'NSP']\n",
    "data = data[selected_cols].dropna()\n",
    "\n",
    "# Shuffle the dataset.\n",
    "data_shuffled = data.sample(frac=1.0, random_state=0)\n",
    "\n",
    "# Split into input part X and output part Y.\n",
    "X = data_shuffled.drop('NSP', axis=1)\n",
    "\n",
    "# Map the diagnosis code to a human-readable label.\n",
    "def to_label(y):\n",
    "    return [None, 'normal', 'suspect', 'pathologic'][(int(y))]\n",
    "\n",
    "Y = data_shuffled['NSP'].apply(to_label)\n",
    "\n",
    "# Partition the data into training and test sets.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca5fc5-7d22-4fe9-9b56-2fbb64a74a27",
   "metadata": {},
   "source": [
    "Step 2. Training the baseline classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73d09a4a-d867-4aff-8219-4e1d9c0b2373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "clf = DummyClassifier(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77a9c499-36df-433d-88b6-58e7d6a1f346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9241176470588235"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "np.average(cross_val_score(clf, Xtrain, Ytrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9ae66b-1e20-42eb-a1dd-5477c844d50c",
   "metadata": {},
   "source": [
    "Step 3. Trying out some different classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "abc8aa36-85cf-4d18-949d-16cca50091c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(random_state=0, max_depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9487ba72-d9f2-4d0d-8291-629244c2c235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9382352941176471"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(cross_val_score(dtc, Xtrain, Ytrain, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef5d1113-e7d5-4b9c-9279-fb8254c1dd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9323529411764706"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(max_depth=6, random_state=0)\n",
    "np.average(cross_val_score(rfc, Xtrain, Ytrain, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1706f505-189c-4253-bb18-0a16f8d6a706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8864705882352941"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lgr = LogisticRegression(random_state=0,max_iter=1000, solver='newton-cg')\n",
    "np.average(cross_val_score(lgr, Xtrain, Ytrain, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d38e07e-abd0-497a-96c1-89b2ceb7bbb3",
   "metadata": {},
   "source": [
    "Step 4. Final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e455666-14e3-430c-961f-41db2206974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892018779342723\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Decision Tree\n",
    "# hyperparameter: max_depth -> 6 seems to be the best parameter\n",
    "from sklearn.metrics import accuracy_score\n",
    "  \n",
    "dtc.fit(Xtrain, Ytrain)\n",
    "Yguess = dtc.predict(Xtest)\n",
    "print(accuracy_score(Ytest, Yguess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "612d30e1-4d44-4501-8d57-39aaa8d421b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9131455399061033\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Random Forest\n",
    "# hyperparameter: max_depth -> again 6 seems to be the best paramater\n",
    "rfc.fit(Xtrain, Ytrain)\n",
    "Yguess = rfc.predict(Xtest)\n",
    "print(accuracy_score(Ytest, Yguess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "af25ac64-8cf0-4fb3-b033-282c8a676336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892018779342723\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Logistic Regression\n",
    "# hyperparameter: solver:  'lbfgs' -> does not work, 'liblinear'->0.87 accuracy, 'newton-cg'->0.89 best accuracy, 'sag'-> does not work, and 'saga'-> does not work.\n",
    "lgr.fit(Xtrain, Ytrain)\n",
    "Yguess = lgr.predict(Xtest)\n",
    "print(accuracy_score(Ytest, Yguess))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab9e206-b2a5-4dba-bf07-a789e727575e",
   "metadata": {},
   "source": [
    "In the cross validation Decision Tree and Random Forest had high average scores whereas Logistic Regression did not perform well. <br>\n",
    "However when looking at the accuracy of the training sets the random forest performed the best. Interestingly Decision Tree performs exactly the same as Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78aa6ed-b8cd-42fe-b7d2-c51505f8f1f7",
   "metadata": {},
   "source": [
    "<h3>Task 2: Decision trees for classification</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea840d16-eeca-4d4c-8f8c-6bc5343cf983",
   "metadata": {},
   "source": [
    "<h3>Task 3: A regression example: predicting apartment prices</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a9e55c1e-1f04-4386-a1d1-751287920092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file using Pandas.\n",
    "alldata = pd.read_csv('sberbank.csv')\n",
    "\n",
    "# Convert the timestamp string to an integer representing the year.\n",
    "def get_year(timestamp):\n",
    "    return int(timestamp[:4])\n",
    "alldata['year'] = alldata.timestamp.apply(get_year)\n",
    "\n",
    "# Select the 7 input columns and the output column.\n",
    "selected_columns = ['price_doc', 'year', 'full_sq', 'life_sq', 'floor', 'num_room', 'kitch_sq', 'full_all']\n",
    "alldata = alldata[selected_columns]\n",
    "alldata = alldata.dropna()\n",
    "\n",
    "# Shuffle.\n",
    "alldata_shuffled = alldata.sample(frac=1.0, random_state=0)\n",
    "\n",
    "# Separate the input and output columns.\n",
    "X = alldata_shuffled.drop('price_doc', axis=1)\n",
    "# For the output, we'll use the log of the sales price.\n",
    "Y = alldata_shuffled['price_doc'].apply(np.log)\n",
    "\n",
    "# Split into training and test sets.\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d5990881-73da-4894-b78a-bc413ca43d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.        , 0.        , 0.00771284, 0.        , 0.        ]),\n",
       " 'score_time': array([0., 0., 0., 0., 0.]),\n",
       " 'test_score': array([-0.39897319, -0.37113485, -0.38083108, -0.39057156, -0.40475168])}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "m1 = DummyRegressor()\n",
    "cross_validate(m1, Xtrain, Ytrain, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3a333548-e5ce-4389-8613-cbff7ea9e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "lso = linear_model.Lasso(alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "db416d81-c8dd-41f2-adba-4dbb37e45439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32604901387710894"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lso.fit(Xtrain, Ytrain)\n",
    "mean_squared_error(Ytest, lso.predict(Xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c707d72-e2c0-4d09-ad8c-e02b466c8c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30696994385672405"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "rfr.fit(Xtrain, Ytrain)\n",
    "\n",
    "mean_squared_error(Ytest, rfr.predict(Xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e6b96d-96a7-4a15-9208-29daa9ae526f",
   "metadata": {},
   "source": [
    "For this task we tried the Lasso and the Random Forest Regressor. We evaluated both models with the mean squarred error. The less the better. In this case the Random Forest Regressor performed better than Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd01c88f-6a29-4371-ae17-ddad8e4bc825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
